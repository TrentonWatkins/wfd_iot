{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to Resources I used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://huggingface.co/TheBloke/Luna-AI-Llama2-Uncensored-GGUF\n",
    "\n",
    "2. https://github.com/abetlen/llama-cpp-python\n",
    "\n",
    "3. https://www.youtube.com/watch?v=-BidzsQYZM4&ab_channel=ChrisHay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "llm = Llama(model_path=\"luna-ai-llama2-uncensored.Q4_K_M.gguf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample below is an example of how to prompt LLAMA 2 on how to use hping for a flooding attack. Note that the AI is not always consistent. From my testing, I have noticed that the AI always provides a command but the parameters always change. Something to possibly consider is maybe specifying the parameters for a flooding attack. But ask Dr. Azab first to see if this is appropriate. Note the output is a dictionary with various key and values. You will have to parse the data out yourselves. Manipulate the code however you feel is best and report the best observations. Runtime for me is 2 - 4 seconds. Since there are two of you, maybe also try out other LLMs and see which one works best. Note that this script is only for GGUF Files ONLY!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'Q: Provide the command line command for performing a flooding attack using hping on IP address 123.123.123.123. Provide the command with no other words or text! A: `hping -c 500 -m 1000 -i 123.123.123.123`', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}]\n"
     ]
    }
   ],
   "source": [
    "output = llm(\n",
    "      \"Q: Provide the command line command for performing a flooding attack using hping on IP address 123.123.123.123. Provide the command with no other words or text! A:\", # Prompt\n",
    "      max_tokens=100, # Generate up to 32 tokens\n",
    "      stop=[\"Q:\", \"\\n\"], # Stop generating just before the model would generate a new question\n",
    "      echo=True, # Echo the prompt back in the output\n",
    ")\n",
    "print(output[\"choices\"]) #Note: I have provided partial extraction of the data, you will have to do the rest. But the answer is generated after \"A:\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
