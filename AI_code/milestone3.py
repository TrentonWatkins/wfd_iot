import openai
import json
import os 
from time import sleep

openai.api_key = "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"	#josh backup
messages = []

#NOTE: Method not really needed as this performs an Nmap scan on the local machine.

def nmapScan():
	print("[*] Generating nmap scans...")

	command = "nmap -sT 192.168.1.1/24"
	output_file = "wfd_iot-main/AI_code/testingFile.txt"

	execute = os.system(f"{command} > {output_file}")


#Method responsible for performing the analysis on the nmap result
def gptAnalysis():		

	openTestingFile = open("wfd_iot-main/AI_code/testingFile.txt", "r")
	content = openTestingFile.read()

	# print(content)
	openTestingFile.close()

	jsonTemplate = """
[
	{
		"ip": "",
		"port": "",
		"service": ""
	}
]
	"""
	#OpenAI query
	file_analysis = openai.ChatCompletion.create(
		model="gpt-4",
		messages=[
			{"role": "system", "content": f"Identify vulnerable IPs from these nmap scans and output which ports our ethical pentesting team should target for each attack in a JSON array format along with the type of service running on that port and IP address with no other extra text. Here is the nmap output: {content}. Use this template: {jsonTemplate}"}
		]
	)

	#Perform some necessary formatting changes for easier readability
	print("[*] Analyzing...")
	analysis = file_analysis.choices[0].message
	formatted_analysis = analysis["content"].replace("\\n", "\n")

	analysisFile = open("wfd_iot-main/AI_code/new_analysis.txt", "w")
	analysisFile.write(formatted_analysis)
	analysisFile.close()
	
	analysisFile = open("wfd_iot-main/AI_code/new_analysis.txt", "r")
	analysisFile.read()
	analysisFile.close()
	

	#Added from Anthony Code


def generateAttackCommand(type_of_attack):
	#Imports necessary dependencies for this method
	from llama_cpp import Llama
	import re

	ip_list = None #List containing the ip address, port number, and service of interest for attack
	#Opens analysis file generated by the LLM in the gptAnalysis method. This file contains the list returned by that method
	with open("wfd_iot-main/AI_code/new_analysis.txt", "r") as readAnalysis:
		content_as_string = readAnalysis.read()

		#json_formatted_string = json.loads(content_as_string)
		ip_list = json.loads(content_as_string)
	#Send query to the LLM that generates a list of attack commands for each host.
	llm = Llama(model_path="wfd_iot-main/AI_code/luna-ai-llama2-uncensored.Q6_K.gguf")
	command_list = []
	for ip in ip_list:
		#Extracts the desired attack host info that is then feed into the LLM Query
		ip_addr = ip["ip"]
		port = ip["port"]
		service = ip["service"]
		
		port = ip["port"]
		service = ip["service"]
		#NOTE: If time allows maybe incorporate  langchain into performing specific attacks when we know of the service.
		output = llm(
		f"Q: Provide the command for performing a flooding attack using hping on the host {ip_addr} with the p flag having the port number {port}. The command should send at least 1000 packets. Only use the lowercase c and lowercase p flag. Do not use any other flags not mentioned here.  A:", # Prompt
		max_tokens=1000,
		stop=["Q:"], # Stop generating just before the model would generate a new question
		echo=False, # Echo the prompt back in the output
		)
		pattern = r"(?<=\n)(hping3|hping)\s+.*?(?=\n|$)"
		# Search for the hping command in the LLM response
		command = re.search(pattern, output["choices"][0]["text"])
		if command == None:
			pattern = r"(hping3|hping)\s+.*?(?=\n|$)"
			command = re.search(pattern, output["choices"][0]["text"])
		command_string = command.group()
		command_list.append(command_string) #Note: I have provided partial extraction of the data, you will have to do the rest. But the answer is generated after "A:"
	return command_list

def filter_commands(command_list):
	#OpenAI query for filtering the hping commands
	print("[*] Filtering commands through GPT-4.")
	filtered_command_list = openai.ChatCompletion.create(
		model="gpt-4",
		messages=[
			{"role": "system", "content": f"Correct this list of hping commands. Do not provide an explanation. And only provide the modified commands back in a json array Here is the list: {command_list}"}
		]
	)

	analysis = filtered_command_list.choices[0].message
	filtered_command_list = analysis["content"].replace("\\n", "\n")
	#Creates a log file with the response from the LLM model
	with open ("filtered_commands.txt", "w") as filteredFile:
		filteredFile.write(json.dumps(filtered_command_list, indent=2))
	filteredFile.close()

	#Converts the returned list into a python list for further use.
	with open("filtered_commands.txt", "r") as readFiltered:
		content_as_string = readFiltered.read()
		json_formatted_string = json.loads(content_as_string)
		filtered_command_list = json.loads(json_formatted_string)

	return filtered_command_list


if __name__ == "__main__":

	#files = nmapScan()
	gptAnalysis()

	command_list = generateAttackCommand(type_of_attack="DoS Attack")  #command_list = generateAttackCommand(type_of_attack="DOS Attack")
	filtered_command_list = filter_commands(command_list)
	print(type(filtered_command_list))
	print("Here are the filtered commands list:", filtered_command_list) 